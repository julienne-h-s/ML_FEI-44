# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞ —Ä–æ–±–æ—Ç–∞ 2: –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è

## üìã –û–ø–∏—Å –∑–∞–≤–¥–∞–Ω–Ω—è

–†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó **–∑ –Ω—É–ª—è** –¥–ª—è –±—ñ–Ω–∞—Ä–Ω–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –º–µ–¥–∏—á–Ω–∏—Ö —Ç–µ—Å—Ç—ñ–≤.

### –¶—ñ–ª—ñ:
1. –†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –ª–æ–≥—ñ—Å—Ç–∏—á–Ω—É —Ä–µ–≥—Ä–µ—Å—ñ—é –±–µ–∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≥–æ—Ç–æ–≤–∏—Ö –±—ñ–±–ª—ñ–æ—Ç–µ–∫ (sklearn)
2. –ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ **SGD** vs **Mini-batch Gradient Descent**
3. –ó–∞—Å—Ç–æ—Å—É–≤–∞—Ç–∏ **L1 (Lasso)** —Ç–∞ **L2 (Ridge)** —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—é
4. –û—Ü—ñ–Ω–∏—Ç–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –º–µ—Ç—Ä–∏–∫ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó

---

## üìä –î–∞—Ç–∞—Å–µ—Ç

**–§–∞–π–ª**: `healthcare_dataset.csv`

### –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:
- **–†–æ–∑–º—ñ—Ä**: 55,500 –∑–∞–ø–∏—Å—ñ–≤ –ø–∞—Ü—ñ—î–Ω—Ç—ñ–≤
- **–û–∑–Ω–∞–∫–∏**: 
  - –ß–∏—Å–ª–æ–≤—ñ: Age, Billing Amount
  - –ö–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ: Gender, Blood Type, Medical Condition, Insurance Provider, Admission Type, Medication
- **–¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞**: Test Results
  - **Normal** ‚Üí 1 (33%)
  - **Abnormal/Inconclusive** ‚Üí 0 (67%)

### –ü—Ä–æ–±–ª–µ–º–∏ –¥–∞—Ç–∞—Å–µ—Ç—É:
- ‚ö†Ô∏è **–ù–µ–∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ—Å—Ç—å –∫–ª–∞—Å—ñ–≤**: —Å–ø—ñ–≤–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è 2:1
- ‚ö†Ô∏è **–°–ª–∞–±–∫—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó**: –≤—Å—ñ –æ–∑–Ω–∞–∫–∏ –º–∞—é—Ç—å –∫–æ—Ä–µ–ª—è—Ü—ñ—é < 0.01 –∑ —Ü—ñ–ª—å–æ–≤–æ—é –∑–º—ñ–Ω–Ω–æ—é

---

## üîß –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö

1. **–ö–æ–¥—É–≤–∞–Ω–Ω—è —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó**:
   - Normal ‚Üí 1
   - Abnormal + Inconclusive ‚Üí 0

2. **One-Hot Encoding**:
   - 6 –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö ‚Üí 32 —á–∏—Å–ª–æ–≤—ñ –æ–∑–Ω–∞–∫–∏

3. **–†–æ–∑–ø–æ–¥—ñ–ª –¥–∞–Ω–∏—Ö**:
   - Train: 60% (33,300 –∑–∞–ø–∏—Å—ñ–≤)
   - Validation: 20% (11,100 –∑–∞–ø–∏—Å—ñ–≤)
   - Test: 20% (11,100 –∑–∞–ø–∏—Å—ñ–≤)
   - –°—Ç—Ä–∞—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –±–∞–ª–∞–Ω—Å—É –∫–ª–∞—Å—ñ–≤

4. **–ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è**:
   - StandardScaler (Œº=0, œÉ=1)

---

## üßÆ –†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ

### –û—Å–Ω–æ–≤–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏:

#### 1. Sigmoid —Ñ—É–Ω–∫—Ü—ñ—è
```python
sigmoid(z) = 1 / (1 + exp(-z))
```
- –ó numerical stability (np.clip –¥–ª—è –∑–∞–ø–æ–±—ñ–≥–∞–Ω–Ω—è overflow)

#### 2. Binary Cross-Entropy Loss
```python
Loss = -1/m * Œ£[y*log(≈∑) + (1-y)*log(1-≈∑)]
```
- –ó —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—î—é L1/L2

#### 3. Gradient Descent
**SGD (Stochastic)**: batch_size = 1
- –®–≤–∏–¥—à–µ –Ω–∞–≤—á–∞–Ω–Ω—è
- –í–∏—Å–æ–∫–∞ –≤–∞—Ä—ñ–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å

**Mini-batch**: batch_size = 32
- –°—Ç–∞–±—ñ–ª—å–Ω—ñ—à–∞ –∑–±—ñ–∂–Ω—ñ—Å—Ç—å
- –ö—Ä–∞—â–∏–π –±–∞–ª–∞–Ω—Å —à–≤–∏–¥–∫–æ—Å—Ç—ñ/—Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ

#### 4. Early Stopping
- Patience = 10 epochs
- –ó–∞–ø–æ–±—ñ–≥–∞—î –ø–µ—Ä–µ–æ–±—É—á–∞–Ω–Ω—é

#### 5. –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è
**L2 (Ridge)**: Œª = 0.1
```python
Penalty = Œª/2 * ||w||¬≤
```

**L1 (Lasso)**: Œª = 0.1
```python
Penalty = Œª * ||w||‚ÇÅ
```

---

## üìà –†–µ–∑—É–ª—å—Ç–∞—Ç–∏

### –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π:

| –ú–æ–¥–µ–ª—å          | Accuracy | Precision | Recall  | F1-Score |
|-----------------|----------|-----------|---------|----------|
| SGD             | 0.6610   | 0.3148    | 0.0138  | 0.0264   |
| Mini-batch      | 0.6664   | 0.0000    | 0.0000  | 0.0000   |
| Mini-batch + L2 | 0.6664   | 0.0000    | 0.0000  | 0.0000   |
| Mini-batch + L1 | 0.6664   | 0.0000    | 0.0000  | 0.0000   |

### –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:

**SGD**:
- –ô–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ: 0.16 - 0.58
- 162 –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∫–ª–∞—Å—É 1

**Mini-batch**:
- –ô–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ: 0.28 - 0.39
- 0 –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å –∫–ª–∞—Å—É 1 (–≤—Å—ñ < 0.5)

### –ü—Ä–æ–±–ª–µ–º–∞:
Mini-batch –º–æ–¥–µ–ª—ñ –ø–µ—Ä–µ–¥–±–∞—á–∞—é—Ç—å —Ç—ñ–ª—å–∫–∏ –∫–ª–∞—Å 0 —á–µ—Ä–µ–∑:
1. –°–∏–ª—å–Ω—É –Ω–µ–∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ—Å—Ç—å –∫–ª–∞—Å—ñ–≤
2. –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ñ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º—É
3. –°–ª–∞–±–∫—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –æ–∑–Ω–∞–∫ –∑ target

---

## üìä –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó

1. **Learning Curves** - –¥–∏–Ω–∞–º—ñ–∫–∞ train/validation loss
2. **Confusion Matrices** - –º–∞—Ç—Ä–∏—Ü—ñ –ø–æ–º–∏–ª–æ–∫ –¥–ª—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π
3. **Metrics Comparison** - –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω—ñ bar charts
4. **Probability Distributions** - —Ä–æ–∑–ø–æ–¥—ñ–ª –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∏—Ö –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π
5. **Correlation Matrix** - heatmap –∫–æ—Ä–µ–ª—è—Ü—ñ–π

---

## üí° –í–∏—Å–Ω–æ–≤–∫–∏

### –©–æ –ø—Ä–∞—Ü—é—î:
‚úÖ SGD –ø–æ–∫–∞–∑—É—î –¥–µ—è–∫—ñ –ø—Ä–∞–≤–∏–ª—å–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è (–Ω–∏–∑—å–∫–∏–π F1, –∞–ª–µ > 0)
‚úÖ Mini-batch –∑–∞–±–µ–∑–ø–µ—á—É—î —Å—Ç–∞–±—ñ–ª—å–Ω—É –∑–±—ñ–∂–Ω—ñ—Å—Ç—å
‚úÖ Early stopping –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∑–∞–ø–æ–±—ñ–≥–∞—î –ø–µ—Ä–µ–æ–±—É—á–∞–Ω–Ω—é
‚úÖ –†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –≤—Å—ñ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤ –∑ –Ω—É–ª—è

### –©–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ –ø–æ–∫—Ä–∞—â–∏—Ç–∏:
‚ùå Mini-batch –∑–∞–Ω–∞–¥—Ç–æ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∏–π –¥–ª—è –º–µ–Ω—à–∏–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—É
‚ùå –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è –Ω–µ –≤–∏—Ä—ñ—à—É—î –ø—Ä–æ–±–ª–µ–º—É –Ω–µ–∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ—Å—Ç—ñ
‚ùå –°–ª–∞–±–∫—ñ features –ø–æ—Ç—Ä–µ–±—É—é—Ç—å feature engineering

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:
1. **Class Weighting**: –≤—Ä–∞—Ö—É–≤–∞–Ω–Ω—è –Ω–µ–∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ—Å—Ç—ñ —É loss function
2. **SMOTE**: —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –º–µ–Ω—à–∏–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—É
3. **Threshold Tuning**: –∑–Ω–∏–∂–µ–Ω–Ω—è –ø–æ—Ä–æ–≥—É –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó (0.5 ‚Üí 0.33)
4. **Feature Engineering**: —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–∏—Ö –æ–∑–Ω–∞–∫ –∑ –≤–∏—â–æ—é –∫–æ—Ä–µ–ª—è—Ü—ñ—î—é
5. **Ensemble Methods**: –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è SGD + Mini-batch

---

## üöÄ –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è

### –ó–∞–ø—É—Å–∫ Notebook:
```bash
jupyter lab lab2_logistic_regression.ipynb
```

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª—ñ–≤:
```
lab2/
‚îú‚îÄ‚îÄ healthcare_dataset.csv          # –î–∞—Ç–∞—Å–µ—Ç
‚îú‚îÄ‚îÄ lab2_logistic_regression.ipynb  # –û—Å–Ω–æ–≤–Ω–∏–π notebook
‚îî‚îÄ‚îÄ README.md                        # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è
```

---

## üìö –ù–∞–≤—á–∞–ª—å–Ω—ñ —Ü—ñ–ª—ñ –¥–æ—Å—è–≥–Ω—É—Ç—ñ:

1. ‚úÖ –†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó –∑ –Ω—É–ª—è
2. ‚úÖ –†–æ–∑—É–º—ñ–Ω–Ω—è —Ä—ñ–∑–Ω–∏—Ü—ñ SGD vs Mini-batch GD
3. ‚úÖ –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è L1/L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó
4. ‚úÖ –†–æ–±–æ—Ç–∞ –∑ –Ω–µ–∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–º–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏
5. ‚úÖ –ê–Ω–∞–ª—ñ–∑ —Ç–∞ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è –º–µ—Ç—Ä–∏–∫ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
6. ‚úÖ –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º –º–æ–¥–µ–ª—ñ

---

## üîó –ó–≤'—è–∑–æ–∫ –∑ —Ç–µ–æ—Ä—ñ—î—é

- **Sigmoid —Ñ—É–Ω–∫—Ü—ñ—è**: –∞–∫—Ç–∏–≤–∞—Ü—ñ—è –¥–ª—è –±—ñ–Ω–∞—Ä–Ω–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
- **Cross-Entropy**: optimal loss –¥–ª—è –π–º–æ–≤—ñ—Ä–Ω—ñ—Å–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π
- **Gradient Descent**: –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –≤–∞–≥ —á–µ—Ä–µ–∑ –ø–æ—Ö—ñ–¥–Ω—ñ
- **Regularization**: penalty –∑–∞ —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ
- **Early Stopping**: –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —á–∏—Å–ª–∞ –µ–ø–æ—Ö

---

**–ê–≤—Ç–æ—Ä**: Andriy  
**–î–∞—Ç–∞**: 2025  
**–ö—É—Ä—Å**: Machine Learning, LNU
